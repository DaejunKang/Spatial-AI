# Preprocessing Stage ì„¸ë¶€ í”„ë¡œì„¸ìŠ¤ ë¶„ì„

## ğŸ“‹ ëª©í‘œ
**Inpaintingì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹ ë° LiDAR-Image ë™ê¸°í™”/íˆ¬ì˜**

---

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1ï¸âƒ£ **Multi-Imageì™€ LiDAR ë°ì´í„° ì‹œê³µê°„ ë™ê¸°í™” ë° Projection**
- LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ë‹¤ì¤‘ ë·° ì´ë¯¸ì§€ì— íˆ¬ì˜
- íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ì„¼ì„œ ë™ê¸°í™”
- ê¹Šì´ ë§µ ìƒì„± (Depth supervisionìš©)

### 2ï¸âƒ£ **ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹ (Masking)**
- 3D Bounding Box íˆ¬ì˜ ê¸°ë°˜ ì •ë°€ ë§ˆìŠ¤í‚¹
- Semantic Segmentation ë³´ì™„ (ì„ íƒì )
- Inpainting Stageì˜ í•µì‹¬ Input ì œê³µ

---

## ğŸ“‚ Preprocessing Stage íŒŒì¼ êµ¬ì¡°

```
Photo-real_project/preprocessing/
â”œâ”€â”€ lidar_projection.py           # LiDAR â†’ Image íˆ¬ì˜ (NEW)
â”œâ”€â”€ dynamic_masking.py            # ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹ (NEW)
â”œâ”€â”€ segmentation.py               # Semantic Segmentation (ê¸°ì¡´)
â”œâ”€â”€ run_preprocessing.py          # í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ì—…ë°ì´íŠ¸)
â”œâ”€â”€ waymo2nre.py                  # Waymo â†’ NRE ë³€í™˜
â”œâ”€â”€ waymo2colmap.py               # COLMAP ì¤€ë¹„
â””â”€â”€ create_nre_pairs.py           # NeRF í•™ìŠµìš© í˜ì–´ ìƒì„±
```

---

## ğŸ› ï¸ ì„¸ë¶€ í”„ë¡œì„¸ìŠ¤ë³„ Input/Output

### 1ï¸âƒ£ **LiDAR Point Cloud Projection** (`lidar_projection.py`)

#### âœ¨ ëª©ì 
- LiDAR 3D í¬ì¸íŠ¸ë¥¼ ë‹¤ì¤‘ ì¹´ë©”ë¼ ì´ë¯¸ì§€ì— íˆ¬ì˜
- ê¹Šì´ ë§µ ìƒì„± (Inpainting Step 2ì—ì„œ í™œìš©)
- ì‹œê³µê°„ ë™ê¸°í™” ê²€ì¦

#### ğŸ“¥ Input
| í•­ëª© | í˜•ì‹ | ì„¤ëª… | ì¶œì²˜ |
|-----|------|------|------|
| Point Clouds | `*.bin` | LiDAR í¬ì¸íŠ¸ (Nx3 float32, Local World ì¢Œí‘œê³„) | Parsing Stage |
| Poses | `*.json` | í”„ë ˆì„ë³„ ì¹´ë©”ë¼ í¬ì¦ˆ/ë©”íƒ€ë°ì´í„° | Parsing Stage |
| Images | `*.jpg` | ì›ë³¸ ì´ë¯¸ì§€ (ê²€ì¦ìš©) | Parsing Stage |

#### âš™ï¸ Process

**1.1 ë°ì´í„° ë¡œë”© ë° ë™ê¸°í™”**
```python
# 1. í”„ë ˆì„ë³„ ì²˜ë¦¬
for frame in frames:
    # LiDAR í¬ì¸íŠ¸ ë¡œë“œ (Local World ì¢Œí‘œê³„)
    points_world = np.fromfile(f"{frame}.bin", dtype=np.float32).reshape(-1, 3)
    
    # ì¹´ë©”ë¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    with open(f"{frame}.json") as f:
        frame_data = json.load(f)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸ (ì‹œê³µê°„ ë™ê¸°í™”)
    timestamp = frame_data['timestamp']
```

**1.2 ì¢Œí‘œ ë³€í™˜ (World â†’ Camera)**
```python
# ê° ì¹´ë©”ë¼ë³„ íˆ¬ì˜
for cam_name, cam_data in frame_data['cameras'].items():
    # Camera Pose (4x4)
    T_cam_to_world = np.array(cam_data['pose']).reshape(4, 4)
    T_world_to_cam = np.linalg.inv(T_cam_to_world)
    
    # í¬ì¸íŠ¸ ë³€í™˜
    points_world_homo = np.hstack([points_world, np.ones((N, 1))])
    points_cam = (T_world_to_cam @ points_world_homo.T).T[:, :3]
    
    # ì¹´ë©”ë¼ ì•ì˜ í¬ì¸íŠ¸ë§Œ ì„ íƒ (Z > 0.1m)
    valid_points = points_cam[points_cam[:, 2] > 0.1]
```

**1.3 3D â†’ 2D íˆ¬ì˜ (with Distortion)**
```python
# OpenCV projectPoints ì‚¬ìš©
intrinsics = cam_data['intrinsics']  # [fx, fy, cx, cy, k1, k2, p1, p2, k3]

fx, fy, cx, cy = intrinsics[:4]
k1, k2, p1, p2, k3 = intrinsics[4:9]

camera_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])
dist_coeffs = np.array([k1, k2, p1, p2, k3])

# íˆ¬ì˜ (ì™œê³¡ ë³´ì • í¬í•¨)
projected_2d, _ = cv2.projectPoints(
    valid_points, 
    rvec=np.zeros(3), 
    tvec=np.zeros(3),
    camera_matrix, 
    dist_coeffs
)

# ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ í¬ì¸íŠ¸ë§Œ ì„ íƒ
valid_mask = (projected_2d[:, 0] >= 0) & (projected_2d[:, 0] < width) & \
             (projected_2d[:, 1] >= 0) & (projected_2d[:, 1] < height)
```

**1.4 ê¹Šì´ ë§µ ìƒì„±**
```python
# í¬ì†Œ ê¹Šì´ ë§µ ì´ˆê¸°í™”
depth_map = np.zeros((height, width), dtype=np.float32)
count_map = np.zeros((height, width), dtype=np.uint16)

# ê° í¬ì¸íŠ¸ì˜ ê¹Šì´ ê°’ ëˆ„ì 
for (x, y), depth in zip(projected_2d, depths):
    depth_map[y, x] += depth
    count_map[y, x] += 1

# í‰ê·  ê³„ì‚° (ì¤‘ë³µ íˆ¬ì˜ ì²˜ë¦¬)
valid_mask = count_map > 0
depth_map[valid_mask] /= count_map[valid_mask]

# ë³´ê°„ (ì„ íƒì )
if interpolation == 'nearest':
    depth_map = cv2.inpaint(
        depth_map, 
        (1 - valid_mask).astype(np.uint8), 
        inpaintRadius=5, 
        flags=cv2.INPAINT_NS
    )

# mm ë‹¨ìœ„ uint16 ë³€í™˜ (ì €ì¥ìš©)
depth_map_mm = (depth_map * 1000).astype(np.uint16)
```

**1.5 í¬ì¸íŠ¸ ë§ˆìŠ¤í¬ ìƒì„±**
```python
# LiDAR í¬ì¸íŠ¸ê°€ íˆ¬ì˜ëœ í”½ì…€ í‘œì‹œ
point_mask = np.zeros((height, width), dtype=np.uint8)

for x, y in projected_2d:
    point_mask[y, x] = 255

# ì‹œê°í™” ê°œì„ ì„ ìœ„í•œ íŒ½ì°½
kernel = np.ones((3, 3), np.uint8)
point_mask = cv2.dilate(point_mask, kernel, iterations=1)
```

#### ğŸ“¤ Output
| ë””ë ‰í† ë¦¬ | íŒŒì¼ í˜•ì‹ | ë‚´ìš© | ìš©ë„ |
|---------|----------|------|------|
| `depth_maps/{cam_name}/` | `{frame}.png` | ê¹Šì´ ë§µ (uint16, mm ë‹¨ìœ„) | Inpainting Step 2 Geometric Guide |
| `point_masks/{cam_name}/` | `{frame}.png` | LiDAR í¬ì¸íŠ¸ ë§ˆìŠ¤í¬ (uint8) | ê²€ì¦ ë° ì‹œê°í™” |

**Depth Map ì½ê¸°:**
```python
depth_mm = cv2.imread("depth_map.png", cv2.IMREAD_UNCHANGED)  # uint16
depth_m = depth_mm.astype(np.float32) / 1000.0  # meters
```

---

### 2ï¸âƒ£ **Dynamic Object Masking** (`dynamic_masking.py`)

#### âœ¨ ëª©ì 
- Inpaintingì—ì„œ ì œê±°í•  ë™ì  ê°ì²´ ì˜ì—­ ë§ˆìŠ¤í‚¹
- 3D Bounding Box ê¸°ë°˜ ì •ë°€ ë§ˆìŠ¤í‚¹
- Semantic Segmentation ë³´ì™„ (ì„ íƒì )

#### ğŸ“¥ Input
| í•­ëª© | í˜•ì‹ | ì„¤ëª… | ì¶œì²˜ |
|-----|------|------|------|
| Objects | `*.json` | ë™ì  ê°ì²´ 3D Bounding Box | Parsing Stage |
| Poses | `*.json` | í”„ë ˆì„ë³„ ì¹´ë©”ë¼ í¬ì¦ˆ/ë©”íƒ€ë°ì´í„° | Parsing Stage |
| Images | `*.jpg` | ì›ë³¸ ì´ë¯¸ì§€ (Semantic Segìš©) | Parsing Stage |

#### âš™ï¸ Process

**2.1 3D Bounding Box â†’ 2D íˆ¬ì˜**
```python
# ê° ë™ì  ê°ì²´ ì²˜ë¦¬
for obj in objects:
    box_center = obj['box']['center']  # [x, y, z] in World
    box_size = obj['box']['size']      # [length, width, height]
    box_heading = obj['box']['heading'] # Yaw angle (rad)
    
    # 1. 3D Box 8ê°œ ì½”ë„ˆ ìƒì„±
    l, w, h = box_size
    
    # Rotation matrix (Z-axis)
    R_z = np.array([
        [cos(heading), -sin(heading), 0],
        [sin(heading),  cos(heading), 0],
        [0, 0, 1]
    ])
    
    # 8 corners (relative to center)
    corners = [
        [Â±l/2, Â±w/2, Â±h/2]  # 8 combinations
    ]
    
    # Rotate & Translate
    corners_world = R_z @ corners + box_center
```

**2.2 ì¢Œí‘œ ë³€í™˜ ë° íˆ¬ì˜**
```python
    # 2. World â†’ Camera ë³€í™˜
    T_world_to_cam = np.linalg.inv(T_cam_to_world)
    corners_cam = T_world_to_cam @ corners_world_homo
    
    # ì¹´ë©”ë¼ ì•ì˜ ì½”ë„ˆë§Œ ì„ íƒ
    valid_corners = corners_cam[corners_cam[:, 2] > 0.1]
    
    # 3. 3D â†’ 2D íˆ¬ì˜ (with distortion)
    projected_2d = cv2.projectPoints(
        valid_corners, 
        rvec, tvec, 
        camera_matrix, 
        dist_coeffs
    )
```

**2.3 ë§ˆìŠ¤í¬ ìƒì„±**
```python
    # 4. 2D Convex Hull ìƒì„±
    hull = cv2.convexHull(projected_2d)
    
    # 5. ë§ˆìŠ¤í¬ì— ì±„ìš°ê¸° (0 = ë™ì  ê°ì²´)
    cv2.fillConvexPoly(mask, hull, 0)
```

**2.4 Semantic Segmentation ë³´ì™„ (ì„ íƒì )**
```python
# SegFormer ëª¨ë¸ ì‚¬ìš© (ì„ íƒì )
if use_semantic_seg:
    from segmentation import SemanticSegmentor
    
    seg_model = SemanticSegmentor()
    semantic_mask = seg_model.process_image(image_path)
    
    # ë‘ ë§ˆìŠ¤í¬ì˜ êµì§‘í•© (ë” ë³´ìˆ˜ì  ë§ˆìŠ¤í‚¹)
    final_mask = cv2.bitwise_and(bbox_mask, semantic_mask)
```

**2.5 ì•ˆì „ ë§ˆì§„ ì¶”ê°€ (Dilation)**
```python
# Inpainting í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ë§ˆì§„
kernel = np.ones((dilation_size, dilation_size), np.uint8)
final_mask = cv2.erode(final_mask, kernel, iterations=1)
# Erodeë¥¼ ì‚¬ìš©í•˜ë©´ ë™ì  ì˜ì—­(0)ì´ í™•ì¥ë¨
```

#### ğŸ“¤ Output
| ë””ë ‰í† ë¦¬ | íŒŒì¼ í˜•ì‹ | ë‚´ìš© | ìš©ë„ |
|---------|----------|------|------|
| `masks/{cam_name}/` | `{frame}.png` | ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ (uint8) | Inpainting ì „ ë‹¨ê³„ Input |

**ë§ˆìŠ¤í¬ í˜•ì‹:**
- `255` (í°ìƒ‰) = ì •ì  ë°°ê²½ (ìœ íš¨ ì˜ì—­)
- `0` (ê²€ì€ìƒ‰) = ë™ì  ê°ì²´ (Inpainting ëŒ€ìƒ)

---

## ğŸ”„ ì „ì²´ ë°ì´í„° í”Œë¡œìš°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Parsing Stage Output (NRE Format)           â”‚
â”‚  - images/*.jpg                                     â”‚
â”‚  - point_clouds/*.bin                               â”‚
â”‚  - poses/*.json                                     â”‚
â”‚  - objects/*.json                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚
        â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LiDAR         â”‚     â”‚ Dynamic Object   â”‚
â”‚ Projection    â”‚     â”‚ Masking          â”‚
â”‚               â”‚     â”‚                  â”‚
â”‚ - Sync Check  â”‚     â”‚ - 3D Box â†’ 2D    â”‚
â”‚ - 3D â†’ 2D     â”‚     â”‚ - Semantic Seg   â”‚
â”‚ - Depth Map   â”‚     â”‚ - Safety Margin  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚
        â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ depth_maps/  â”‚     â”‚ masks/           â”‚
â”‚ point_masks/ â”‚     â”‚ (0=dynamic)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Inpainting      â”‚
        â”‚ Stage           â”‚
        â”‚                 â”‚
        â”‚ Step 1: Temporalâ”‚
        â”‚ Step 2: Geom    â”‚ â† depth_maps í™œìš©
        â”‚ Step 3: AI Gen  â”‚ â† masks í™œìš©
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### 1. **ì‹œê³µê°„ ë™ê¸°í™” (Temporal-Spatial Sync)**

**ë¬¸ì œ:** LiDARì™€ ì¹´ë©”ë¼ì˜ ì„¼ì‹± íƒ€ì´ë°ì´ ë‹¤ë¦„ (Rolling Shutter)

**í•´ê²°:**
```python
# WaymoëŠ” ì´ë¯¸ ë™ê¸°í™”ëœ ë°ì´í„° ì œê³µ
# í•˜ì§€ë§Œ Rolling Shutter ë³´ì • í•„ìš” (í–¥í›„)

timestamp_lidar = frame_data['timestamp']
timestamp_cam = cam_data['rolling_shutter']['trigger_time']

# í˜„ì¬ëŠ” í”„ë ˆì„ ë‹¨ìœ„ë¡œ 1:1 ë§¤ì¹­
# í–¥í›„ ê°œì„ : Sub-frame interpolation
```

### 2. **ì¹´ë©”ë¼ ì™œê³¡ ë³´ì • (Distortion Correction)**

**Waymo ì¹´ë©”ë¼ ëª¨ë¸:** Brown-Conrady (OpenCV í˜¸í™˜)

**íŒŒë¼ë¯¸í„°:**
- Radial distortion: k1, k2, k3
- Tangential distortion: p1, p2

**ë³´ì • ë°©ë²•:**
```python
# OpenCV projectPointsê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬
cv2.projectPoints(..., dist_coeffs=[k1, k2, p1, p2, k3])
```

### 3. **í¬ì†Œ ê¹Šì´ ë§µ ë³´ê°„ (Sparse Depth Interpolation)**

**ë¬¸ì œ:** LiDAR í¬ì¸íŠ¸ëŠ” í¬ì†Œí•¨ (ì´ë¯¸ì§€ í”½ì…€ì˜ ~1%)

**ë°©ë²•:**

| ë°©ë²• | ì†ë„ | í’ˆì§ˆ | ì‚¬ìš© ì‚¬ë¡€ |
|-----|------|------|----------|
| **None** | ë¹ ë¦„ | ë‚®ìŒ | ê²€ì¦ìš© |
| **Nearest** | ì¤‘ê°„ | ì¤‘ê°„ | Inpainting ê°€ì´ë“œ (ê¶Œì¥) |
| **Linear** | ëŠë¦¼ | ë†’ìŒ | NeRF í•™ìŠµ |
| **Cubic** | ë§¤ìš° ëŠë¦¼ | ë§¤ìš° ë†’ìŒ | ìµœì¢… ì‹œê°í™” |

**êµ¬í˜„ (Nearest):**
```python
# OpenCV inpainting í™œìš©
depth_map_dense = cv2.inpaint(
    depth_map_sparse,
    mask=(depth_map_sparse == 0),
    inpaintRadius=5,
    flags=cv2.INPAINT_NS  # Navier-Stokes
)
```

### 4. **ë™ì  ê°ì²´ ì•ˆì „ ë§ˆì§„ (Safety Margin)**

**ëª©ì :** Inpainting í’ˆì§ˆ í–¥ìƒ (ê°ì²´ ê²½ê³„ Artifact ë°©ì§€)

**ë°©ë²•:**
```python
# ë§ˆìŠ¤í¬ íŒ½ì°½ (Erosion = ë™ì  ì˜ì—­(0) í™•ì¥)
kernel_size = 5  # í”½ì…€
kernel = np.ones((kernel_size, kernel_size), np.uint8)
mask_expanded = cv2.erode(mask, kernel, iterations=1)
```

**ê¶Œì¥ ê°’:**
- Normal: 5x5 (ê¸°ë³¸)
- Conservative (ë” ë„“ê²Œ): 7x7
- Aggressive (ìµœì†Œ): 3x3

---

## ğŸ“Š ì„±ëŠ¥ ë° í’ˆì§ˆ ì§€í‘œ

### LiDAR Projection

| í•­ëª© | ê°’ | ì„¤ëª… |
|-----|---|------|
| **ì²˜ë¦¬ ì†ë„** | ~5-10 fps | CPU ê¸°ì¤€, ë‹¨ì¼ í”„ë ˆì„ |
| **í¬ì¸íŠ¸ ë°€ë„** | ~100K-200K | í”„ë ˆì„ë‹¹ LiDAR í¬ì¸íŠ¸ |
| **íˆ¬ì˜ ì„±ê³µë¥ ** | ~60-80% | ì´ë¯¸ì§€ ë‚´ë¶€ íˆ¬ì˜ ë¹„ìœ¨ |
| **ê¹Šì´ ë²”ìœ„** | 0.1m - 80m | Waymo LiDAR ìœ íš¨ ë²”ìœ„ |
| **ê¹Šì´ ì •ë°€ë„** | ~mm ë‹¨ìœ„ | uint16 ì €ì¥ (0-65m) |

### Dynamic Object Masking

| í•­ëª© | ê°’ | ì„¤ëª… |
|-----|---|------|
| **ì²˜ë¦¬ ì†ë„** | ~20-30 fps | 3D Boxë§Œ (Semantic ì œì™¸) |
| **ë§ˆìŠ¤í‚¹ ì •í™•ë„** | ~95%+ | 3D Box ê¸°ì¤€ IoU |
| **ê°ì²´ íƒì§€ ìˆ˜** | ~10-30 | í”„ë ˆì„ë‹¹ í‰ê·  |
| **ì•ˆì „ ë§ˆì§„** | 5 í”½ì…€ | ê¸°ë³¸ ì„¤ì • |

---

## ğŸš€ ì‚¬ìš© ì˜ˆì‹œ

### ì „ì²´ Preprocessing ì‹¤í–‰
```bash
# ëª¨ë“  ë‹¨ê³„ ì‹¤í–‰
python preprocessing/run_preprocessing.py \
    /path/to/waymo_nre_data \
    --all

# ë˜ëŠ” ë‹¨ê³„ë³„ ì‹¤í–‰
python preprocessing/run_preprocessing.py \
    /path/to/waymo_nre_data \
    --lidar \
    --dynamic_mask \
    --semantic
```

### LiDAR Projectionë§Œ ì‹¤í–‰
```bash
python preprocessing/lidar_projection.py \
    /path/to/waymo_nre_data \
    --interpolation nearest
```

### Dynamic Maskingë§Œ ì‹¤í–‰
```bash
# 3D Bounding Boxë§Œ
python preprocessing/dynamic_masking.py \
    /path/to/waymo_nre_data \
    --dilation 5

# Semantic Segmentation í¬í•¨
python preprocessing/dynamic_masking.py \
    /path/to/waymo_nre_data \
    --use_semantic \
    --dilation 7
```

---

## ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
waymo_nre_data/
â”œâ”€â”€ images/                    # [Parsing] ì›ë³¸ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ FRONT/
â”‚   â”œâ”€â”€ FRONT_LEFT/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ point_clouds/              # [Parsing] LiDAR í¬ì¸íŠ¸
â”‚   â””â”€â”€ *.bin
â”œâ”€â”€ poses/                     # [Parsing] ì¹´ë©”ë¼ ë©”íƒ€ë°ì´í„°
â”‚   â””â”€â”€ *.json
â”œâ”€â”€ objects/                   # [Parsing] ë™ì  ê°ì²´
â”‚   â””â”€â”€ *.json
â”œâ”€â”€ depth_maps/                # [Preprocessing] ê¹Šì´ ë§µ (NEW)
â”‚   â”œâ”€â”€ FRONT/
â”‚   â”‚   â””â”€â”€ *.png (uint16)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ point_masks/               # [Preprocessing] LiDAR ë§ˆìŠ¤í¬ (NEW)
â”‚   â”œâ”€â”€ FRONT/
â”‚   â”‚   â””â”€â”€ *.png (uint8)
â”‚   â””â”€â”€ ...
â””â”€â”€ masks/                     # [Preprocessing] ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ (NEW)
    â”œâ”€â”€ FRONT/
    â”‚   â””â”€â”€ *.png (0=dynamic, 255=static)
    â””â”€â”€ ...
```

---

## ğŸ”— Inpainting Stageì™€ì˜ ì—°ê³„

### Step 1: Temporal Accumulation
**Input:**
- `images/`: ì›ë³¸ ì´ë¯¸ì§€
- `masks/`: ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ â† **Preprocessing Output**

**Process:**
ì‹œê³„ì—´ ë°°ê²½ ëˆ„ì ìœ¼ë¡œ ë™ì  ê°ì²´ ì œê±° ì‹œë„

---

### Step 2: Geometric Guide
**Input:**
- `step1_warped/`: Step 1 ê²°ê³¼
- `depth_maps/`: LiDAR ê¹Šì´ ë§µ â† **Preprocessing Output**
- `masks/`: êµ¬ë© ë§ˆìŠ¤í¬

**Process:**
ê¹Šì´ ê°€ì´ë“œë¡œ ë‚¨ì€ êµ¬ë© ì˜ˆì¸¡

---

### Step 3: Final Inpainting
**Input:**
- `step2_depth_guide/`: Step 2 ê²°ê³¼
- `masks/`: ìµœì¢… êµ¬ë© ë§ˆìŠ¤í¬ â† **Preprocessing Output**
- `depth_maps/`: ControlNet ê°€ì´ë“œ â† **Preprocessing Output**

**Process:**
Stable Diffusion + ControlNetìœ¼ë¡œ ìµœì¢… ìƒì„±

---

## ğŸ“ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### ì¢Œí‘œê³„ ë³€í™˜ ì²´ì¸

```
LiDAR Point (Vehicle Frame)
    â†“ [Parsing Stage]
World Point (First Frame Origin)
    â†“ [T_world_to_cam = inv(T_cam_to_world)]
Camera Point (Camera Frame)
    â†“ [projectPoints with distortion]
Image Point (Pixel Coordinates)
```

### ë³€í™˜ í–‰ë ¬ ì •ì˜

```python
# Parsing Stageì—ì„œ ì œê³µ
T_cam_to_world = [
    [R11, R12, R13, tx],
    [R21, R22, R23, ty],
    [R31, R32, R33, tz],
    [  0,   0,   0,  1]
]

# Preprocessingì—ì„œ ê³„ì‚°
T_world_to_cam = np.linalg.inv(T_cam_to_world)
```

### íˆ¬ì˜ ë°©ì •ì‹

```
# 1. Homogeneous coordinates
P_world_homo = [x, y, z, 1]

# 2. Transform to camera frame
P_cam_homo = T_world_to_cam @ P_world_homo
P_cam = P_cam_homo[:3]  # [X, Y, Z]

# 3. Perspective projection (with distortion)
x' = X / Z
y' = Y / Z

# 4. Radial distortion
rÂ² = x'Â² + y'Â²
x'' = x' * (1 + k1*rÂ² + k2*râ´ + k3*râ¶)
y'' = y' * (1 + k1*rÂ² + k2*râ´ + k3*râ¶)

# 5. Tangential distortion
x''' = x'' + 2*p1*x'*y' + p2*(rÂ² + 2*x'Â²)
y''' = y'' + p1*(rÂ² + 2*y'Â²) + 2*p2*x'*y'

# 6. Pixel coordinates
u = fx * x''' + cx
v = fy * y''' + cy
```

---

## ğŸ“ ì¶”ê°€ ê°œì„  ê°€ëŠ¥ ì‚¬í•­

1. **Rolling Shutter ë³´ì •**: í˜„ì¬ëŠ” Static ê°€ì •, ëª¨ì…˜ ë³´ì • ì¶”ê°€
2. **Multi-frame ìœµí•©**: ì—¬ëŸ¬ í”„ë ˆì„ì˜ LiDAR ëˆ„ì ìœ¼ë¡œ ë°€ë„ í–¥ìƒ
3. **í•™ìŠµ ê¸°ë°˜ ê¹Šì´ ë³´ê°„**: CNN/Transformer ê¸°ë°˜ dense depth estimation
4. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: GPU ë³‘ë ¬í™” ë° ìµœì í™” (í˜„ì¬ CPU ê¸°ë°˜)
5. **Occlusion ì²˜ë¦¬**: ë™ì  ê°ì²´ ë’¤ì˜ ë°°ê²½ ë³µì› ì „ëµ

---

## âœ… ìš”êµ¬ì‚¬í•­ ì¶©ì¡± í™•ì¸

| ìš”êµ¬ì‚¬í•­ | êµ¬í˜„ ìœ„ì¹˜ | ìƒíƒœ |
|---------|----------|------|
| **Multi-image & LiDAR ë™ê¸°í™”** | `lidar_projection.py` | âœ… ì™„ë£Œ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜) |
| **LiDAR â†’ Image Projection** | `lidar_projection.py` | âœ… ì™„ë£Œ (ì™œê³¡ ë³´ì • í¬í•¨) |
| **ê¹Šì´ ë§µ ìƒì„±** | `lidar_projection.py` | âœ… ì™„ë£Œ (ë³´ê°„ í¬í•¨) |
| **ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹** | `dynamic_masking.py` | âœ… ì™„ë£Œ (3D Box íˆ¬ì˜) |
| **Semantic Segmentation** | `dynamic_masking.py` + `segmentation.py` | âœ… ì™„ë£Œ (ì„ íƒì ) |
| **ì•ˆì „ ë§ˆì§„** | `dynamic_masking.py` | âœ… ì™„ë£Œ (Dilation) |
| **Inpainting ì—°ê³„** | Output í¬ë§· | âœ… ì™„ë£Œ (í˜¸í™˜) |

---

**ìµœì¢… í™•ì¸ì¼**: 2026-02-05  
**ì‘ì„±ì**: Cloud Agent  
**ë²„ì „**: 1.0
