# Parsing Stage ì„¸ë¶€ í”„ë¡œì„¸ìŠ¤ ë¶„ì„

## ğŸ“‹ ëª©í‘œ
**Waymoì˜ ë°”ì´ë„ˆë¦¬ í¬ë§·(.tfrecord)ì„ í‘œì¤€ íŒŒì¼ í¬ë§·ìœ¼ë¡œ ë³€í™˜ ë° ì •ê·œí™”**

---

## ğŸ” í˜„ì¬ êµ¬í˜„ ìƒíƒœ í™•ì¸

### âœ… êµ¬í˜„ëœ ê¸°ëŠ¥
1. **Frame Alignment**: ì´ë¯¸ì§€, LiDAR, Pose íƒ€ì„ìŠ¤íƒ¬í”„ ë™ê¸°í™”
2. **Coordinate Normalization**: ì²« í”„ë ˆì„ Ego-vehicle ê¸°ì¤€ World ì¢Œí‘œê³„(0,0,0) ì„¤ì •
3. **Rolling Shutter Info**: ì†ë„(v, w) ë° Readout time ì¶”ì¶œ
4. **Dynamic Object Masking**: ë™ì  ê°ì²´ 3Dâ†’2D íˆ¬ì˜ ë° ë§ˆìŠ¤í¬ ìƒì„±

---

## ğŸ“‚ Parsing Stage íŒŒì¼ êµ¬ì¡°

```
Photo-real_project/
â”œâ”€â”€ parsing/
â”‚   â”œâ”€â”€ extract_waymo_data.py              # TensorFlow ì˜ì¡´ ë²„ì „
â”‚   â”œâ”€â”€ extract_waymo_data_minimal.py      # TensorFlow ì œê±° ë²„ì „
â”‚   â”œâ”€â”€ waymo_utils.py                     # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ test_minimal_converter.py          # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ preprocessing/
    â””â”€â”€ waymo2nre.py                        # NRE í¬ë§· ì»¨ë²„í„° (Rolling Shutter í¬í•¨)
```

---

## ğŸ› ï¸ ì„¸ë¶€ í”„ë¡œì„¸ìŠ¤ë³„ Input/Output

### 1ï¸âƒ£ **Waymo2NRE Converter** (`waymo2nre.py`)

#### âœ¨ ëª©ì 
- Waymo TFRecord â†’ NRE(Neural Rendering Engine) í¬ë§· ë³€í™˜
- Rolling Shutter ì •ë³´ í¬í•¨
- ì²« í”„ë ˆì„ ê¸°ì¤€ ì¢Œí‘œê³„ ì •ê·œí™”

#### ğŸ“¥ Input
| í•­ëª© | í˜•ì‹ | ì„¤ëª… |
|-----|------|------|
| TFRecord íŒŒì¼ | `.tfrecord` | Waymo Segment ë°”ì´ë„ˆë¦¬ ë°ì´í„° |
| Load Directory | `String` | TFRecord íŒŒì¼ë“¤ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ |
| Prefix | `String` | ì¶œë ¥ íŒŒì¼ëª… ì ‘ë‘ì‚¬ (ì˜ˆ: `seq0_`) |

#### âš™ï¸ Process

**1.1 TFRecord ì½ê¸° (No TensorFlow)**
```python
MinimalTFRecordReader:
  - TFRecord ë°”ì´ë„ˆë¦¬ êµ¬ì¡° íŒŒì‹±
  - [length(8bytes)][crc(4bytes)][data][crc(4bytes)] ìˆœì°¨ ì½ê¸°
  - CRC ê²€ì¦ ìƒëµ (ì†ë„ ìµœì í™”)
```

**1.2 Frame Alignment**
```python
for each frame in segment:
    - íƒ€ì„ìŠ¤íƒ¬í”„: frame.timestamp_micros / 1e6
    - ì´ë¯¸ì§€: frame.images[].camera_trigger_time
    - ì†ë„: frame.images[0].velocity (v_x, v_y, v_z, w_x, w_y, w_z)
```

**1.3 Coordinate Normalization**
```python
# ì²« í”„ë ˆì„(frame_idx=0)ì„ World Originìœ¼ë¡œ ì„¤ì •
if frame_idx == 0:
    first_frame_pose = np.array(frame.pose.transform).reshape(4, 4)
    world_origin_inv = np.linalg.inv(first_frame_pose)

# ëª¨ë“  í›„ì† í”„ë ˆì„ ì¢Œí‘œ ë³€í™˜
current_pose_global = np.array(frame.pose.transform).reshape(4, 4)
T_vehicle_to_world = world_origin_inv @ current_pose_global

# ì†ë„ ë²¡í„°ë„ ë™ì¼ íšŒì „ ì ìš©
R_inv = world_origin_inv[:3, :3]
v_local = R_inv @ v_global
w_local = R_inv @ w_global
```

**1.4 Rolling Shutter Info ì¶”ì¶œ**
```python
# ê° ì¹´ë©”ë¼ë³„ Rolling Shutter íŒŒë¼ë¯¸í„°
readout = img.rolling_shutter_params.shutter  # ìš°ì„ ìˆœìœ„ 1
if readout == 0.0:
    readout = img.camera_readout_done_time - img.camera_trigger_time  # Fallback

rolling_shutter = {
    "duration": readout,           # ì „ì²´ ë…¸ì¶œ ì‹œê°„ (ì´ˆ)
    "trigger_time": img.camera_trigger_time  # ì‹œì‘ ì‹œê°„
}
```

**1.5 Camera Calibration**
```python
# ê° ì¹´ë©”ë¼ë³„ Intrinsic/Extrinsic
T_cam_to_vehicle = calib.extrinsic.transform  # 4x4
T_cam_to_world = T_vehicle_to_world @ T_cam_to_vehicle

intrinsics = [fx, fy, cx, cy, k1, k2, p1, p2, k3]  # 9 params
```

#### ğŸ“¤ Output
| ë””ë ‰í† ë¦¬ | íŒŒì¼ í˜•ì‹ | ë‚´ìš© |
|---------|----------|------|
| `images/` | `{prefix}{file_idx:03d}{frame_idx:03d}_{cam_name}.jpg` | ì›ë³¸ ì´ë¯¸ì§€ (5 ì¹´ë©”ë¼) |
| `poses/` | `{prefix}{file_idx:03d}{frame_idx:03d}.json` | í”„ë ˆì„ë³„ ë©”íƒ€ë°ì´í„° |
| `objects/` | `{prefix}{file_idx:03d}{frame_idx:03d}.json` | ë™ì  ê°ì²´ ì •ë³´ |

**Pose JSON êµ¬ì¡° (`poses/*.json`)**
```json
{
  "frame_idx": 0,
  "timestamp": 1234567890.123456,
  "ego_velocity": {
    "linear": [vx, vy, vz],      // Local World ì¢Œí‘œê³„ (m/s)
    "angular": [wx, wy, wz]      // Local World ì¢Œí‘œê³„ (rad/s)
  },
  "cameras": {
    "FRONT": {
      "img_path": "images/seq0_000000_FRONT.jpg",
      "width": 1920,
      "height": 1280,
      "intrinsics": [fx, fy, cx, cy, k1, k2, p1, p2, k3],
      "pose": [4x4 matrix flattened],  // T_cam_to_world
      "rolling_shutter": {
        "duration": 0.033,           // ë…¸ì¶œ ì‹œê°„ (ì´ˆ)
        "trigger_time": 1234567890.1 // ì´¬ì˜ ì‹œì‘ ì‹œê°„
      }
    },
    "FRONT_LEFT": {...},
    "FRONT_RIGHT": {...},
    "SIDE_LEFT": {...},
    "SIDE_RIGHT": {...}
  }
}
```

**Objects JSON êµ¬ì¡° (`objects/*.json`)**
```json
[
  {
    "id": "object_id_123",
    "class": "TYPE_VEHICLE",      // TYPE_PEDESTRIAN, TYPE_CYCLIST
    "box": {
      "center": [x, y, z],        // Local World ì¢Œí‘œê³„
      "size": [length, width, height],
      "heading": 1.57              // Yaw angle (rad)
    },
    "speed": [vx, vy]              // 2D ì†ë„ (m/s)
  }
]
```

---

### 2ï¸âƒ£ **Minimal Extractor** (`extract_waymo_data_minimal.py`)

#### âœ¨ ëª©ì 
- COLMAP ì „ì²˜ë¦¬ìš© ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ ì¶”ì¶œ
- TensorFlow ì˜ì¡´ì„± ì œê±°
- ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹

#### ğŸ“¥ Input
| í•­ëª© | í˜•ì‹ | ì„¤ëª… |
|-----|------|------|
| TFRecord íŒŒì¼ | `.tfrecord` | Waymo Segment |
| Input Path | `String` | íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ |

#### âš™ï¸ Process

**2.1 ì´ë¯¸ì§€ ë””ì½”ë”©**
```python
# OpenCV ê¸°ë°˜ ë””ì½”ë”© (No TensorFlow)
np_arr = np.frombuffer(img.image, np.uint8)
img_bgr = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
```

**2.2 ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±**
```python
# 1. 3D Bounding Box â†’ 2D íˆ¬ì˜
for label in frame.laser_labels:
    if label.type in [1, 2, 4]:  # Vehicle, Pedestrian, Cyclist
        # 8ê°œ ì½”ë„ˆ ì  ìƒì„±
        corners_3d = compute_box_corners(label.box)
        
        # Vehicle â†’ Camera ë³€í™˜
        T_c_v = np.linalg.inv(calib.extrinsic)
        corners_cam = T_c_v @ corners_3d
        
        # ì¹´ë©”ë¼ ì™œê³¡ í¬í•¨ íˆ¬ì˜
        projected_2d = cv2.projectPoints(
            corners_cam, 
            r_vec, t_vec, 
            camera_matrix, 
            distortion_coeffs
        )
        
        # 2D Convex Hull ì±„ìš°ê¸°
        hull = cv2.convexHull(projected_2d)
        cv2.fillConvexPoly(mask, hull, 0)  # ê²€ì€ìƒ‰(0)
```

**2.3 Pose ë° Calibration ì €ì¥**
```python
# ê¸€ë¡œë²Œ ì¢Œí‘œê³„ Pose (4x4 matrix)
vehicle_poses[frame_idx] = frame.pose.transform

# ì¹´ë©”ë¼ë³„ Calibration
calibration[cam_name] = {
    "extrinsic": T_cam_to_vehicle,  # 4x4
    "intrinsic": [fx, fy, cx, cy, k1, k2, p1, p2, k3],
    "width": 1920,
    "height": 1280
}
```

#### ğŸ“¤ Output
| ë””ë ‰í† ë¦¬ | íŒŒì¼ í˜•ì‹ | ë‚´ìš© |
|---------|----------|------|
| `images/{cam_name}/` | `{frame_idx:06d}.png` | ì›ë³¸ ì´ë¯¸ì§€ (5 ì¹´ë©”ë¼ë³„ ì„œë¸Œ ë””ë ‰í† ë¦¬) |
| `masks/{cam_name}/` | `{frame_idx:06d}.png` | ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ (í°ìƒ‰=ìœ íš¨, ê²€ì€ìƒ‰=ë™ì ) |
| `poses/` | `vehicle_poses.json` | ì „ì²´ í”„ë ˆì„ Pose ë”•ì…”ë„ˆë¦¬ |
| `calibration/` | `intrinsics_extrinsics.json` | ì¹´ë©”ë¼ Calibration |

**Vehicle Poses JSON êµ¬ì¡°**
```json
{
  "000000": [4x4 matrix flattened],  // Global ì¢Œí‘œê³„
  "000001": [4x4 matrix flattened],
  ...
}
```

**Calibration JSON êµ¬ì¡°**
```json
{
  "FRONT": {
    "extrinsic": [4x4 matrix],      // T_cam_to_vehicle
    "intrinsic": [fx, fy, cx, cy, k1, k2, p1, p2, k3],
    "width": 1920,
    "height": 1280
  },
  ...
}
```

---

### 3ï¸âƒ£ **Common Utilities** (`waymo_utils.py`)

#### ì œê³µ ê¸°ëŠ¥
| í•¨ìˆ˜ | ì„¤ëª… | Input | Output |
|------|------|-------|--------|
| `MinimalTFRecordReader` | TensorFlow ì—†ì´ TFRecord ì½ê¸° | `.tfrecord` path | Data bytes iterator |
| `decode_image_opencv` | OpenCV ì´ë¯¸ì§€ ë””ì½”ë”© | JPEG/PNG bytes | BGR numpy array |
| `get_camera_name_map` | ì¹´ë©”ë¼ ID â†’ Name ë§¤í•‘ | - | Dict {1: 'FRONT', ...} |
| `transform_pose_to_local` | Global â†’ Local ì¢Œí‘œ ë³€í™˜ | Pose(4x4), Origin_inv(4x4) | Local Pose(4x4) |
| `project_3d_box_to_2d` | 3D Box â†’ 2D íˆ¬ì˜ | Box, T_c_v, Intrinsic | 2D points (Nx2) |
| `get_calibration_dict` | Frameì—ì„œ Calibration ì¶”ì¶œ | Waymo Frame | Dict {cam_name: {extrinsic, intrinsic, ...}} |
| `quaternion_to_rotation_matrix` | Quaternion â†’ Rotation | qvec [w,x,y,z] | R (3x3) |
| `rotation_matrix_to_quaternion` | Rotation â†’ Quaternion | R (3x3) | qvec [w,x,y,z] |

---

## âœ… ìš”êµ¬ì‚¬í•­ ì¶©ì¡± í™•ì¸

| ìš”êµ¬ì‚¬í•­ | êµ¬í˜„ ìœ„ì¹˜ | ìƒíƒœ |
|---------|----------|------|
| **Frame Alignment** | `waymo2nre.py` Line 118-133 | âœ… ì™„ë£Œ |
| **Coordinate Normalization** | `waymo2nre.py` Line 122-129 | âœ… ì™„ë£Œ (ì²« í”„ë ˆì„ ê¸°ì¤€) |
| **Rolling Shutter Info** | `waymo2nre.py` Line 194-208 | âœ… ì™„ë£Œ (duration + trigger_time) |
| **Velocity Extraction** | `waymo2nre.py` Line 154-169 | âœ… ì™„ë£Œ (linear + angular) |
| **Output: images_raw/*.jpg** | `waymo2nre.py` Line 176-186 | âœ… ì™„ë£Œ (images/*.jpg) |
| **Output: poses/*.json** | `waymo2nre.py` Line 211-214 | âœ… ì™„ë£Œ |

---

## ğŸ”„ ì „ì²´ ë°ì´í„° í”Œë¡œìš°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Waymo .tfrecord         â”‚
â”‚ (Binary Format)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MinimalTFRecordReader   â”‚
â”‚ (No TensorFlow)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                      â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Images   â”‚        â”‚   Poses    â”‚      â”‚  Objects   â”‚
    â”‚ (5 cameras)â”‚        â”‚ (T + v + w)â”‚      â”‚ (3D Boxes) â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                     â”‚                     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Coordinate Transform  â”‚
                    â”‚ (First Frame = Origin)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ NRE Format Output     â”‚
                    â”‚ - images/*.jpg        â”‚
                    â”‚ - poses/*.json        â”‚
                    â”‚ - objects/*.json      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ í•µì‹¬ íŠ¹ì§•

### 1. **ì¢Œí‘œê³„ ì •ê·œí™”**
- **ì²« í”„ë ˆì„** Ego-vehicle ìœ„ì¹˜ë¥¼ World Origin (0,0,0)ìœ¼ë¡œ ì„¤ì •
- ëª¨ë“  í›„ì† í”„ë ˆì„ì˜ Pose ë° ì†ë„ë¥¼ ì´ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
- **ì¥ì **: NeRF/3DGS í•™ìŠµ ì‹œ ìˆ˜ì¹˜ ì•ˆì •ì„± í–¥ìƒ

### 2. **Rolling Shutter ì²˜ë¦¬**
- **Duration**: ì „ì²´ ë…¸ì¶œ ì‹œê°„ (ë³´í†µ ~33ms)
- **Trigger Time**: ì´¬ì˜ ì‹œì‘ ì‹œê°„ (Sync ê¸°ì¤€)
- **í™œìš©**: NeRF4D ë“±ì—ì„œ ëª¨ì…˜ ë¸”ëŸ¬ ë³´ì •

### 3. **ë™ì  ê°ì²´ ë§ˆìŠ¤í‚¹**
- 3D Bounding Box â†’ 2D Convex Hull íˆ¬ì˜
- OpenCV distortion model ì ìš© (k1~k3, p1~p2)
- **COLMAP ì…ë ¥**: Static ì˜ì—­ë§Œ SfM ì‚¬ìš©

### 4. **ì˜ì¡´ì„± ìµœì†Œí™”**
- TensorFlow ì œê±° â†’ ê²½ëŸ‰ TFRecord Reader ìì²´ êµ¬í˜„
- Pure Python + NumPy + OpenCV
- **ì¥ì **: ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥

---

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

| í•­ëª© | ê°’ |
|-----|---|
| **ì²˜ë¦¬ ì†ë„** | ~1-2 fps (CPU only) |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | ~2GB (Single Segment) |
| **ë””ìŠ¤í¬ ê³µê°„** | ~10GB/Segment (ì´ë¯¸ì§€ + ë©”íƒ€ë°ì´í„°) |
| **ì§€ì› ì¹´ë©”ë¼** | 5ê°œ (FRONT, FRONT_L/R, SIDE_L/R) |
| **ë™ì  ê°ì²´ í´ë˜ìŠ¤** | 3ê°œ (Vehicle, Pedestrian, Cyclist) |

---

## ğŸš€ ì‚¬ìš© ì˜ˆì‹œ

### Waymo2NRE ì‹¤í–‰
```bash
python waymo2nre.py \
    /path/to/tfrecords \
    /path/to/output \
    --prefix seq0_
```

### Minimal Extractor ì‹¤í–‰
```bash
python extract_waymo_data_minimal.py \
    /path/to/segment.tfrecord \
    /path/to/output
```

---

## ğŸ“ ì¶”ê°€ ê°œì„  ê°€ëŠ¥ ì‚¬í•­

1. **LiDAR Point Cloud ì €ì¥**: í˜„ì¬ëŠ” Pose/Imageë§Œ, Depth Ground Truth ì¶”ê°€ ê°€ëŠ¥
2. **Multi-Processing**: í˜„ì¬ Single Thread, ë³‘ë ¬í™”ë¡œ ì†ë„ í–¥ìƒ
3. **COLMAP ìë™ ì—°ë™**: ì¶”ì¶œ í›„ ë°”ë¡œ SfM ì‹¤í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸
4. **LoRA Training Dataset ìë™ ìƒì„±**: Inpaintingìš© í•™ìŠµ ë°ì´í„° ì¤€ë¹„

---

**ìµœì¢… í™•ì¸ì¼**: 2026-02-05  
**ì‘ì„±ì**: Cloud Agent  
**ë²„ì „**: 1.0
