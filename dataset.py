import os
import glob
import numpy as np
import torch
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms

class WaymoExtractedDataset(Dataset):
    """
    Dataset class for loading extracted Waymo Open Dataset data.
    Assumes data was extracted using the 'extract_waymo_data.py' script.
    
    Directory Structure:
        root_dir/
            segment_name_1/
                images/
                    FRONT/
                    FRONT_LEFT/
                    ...
                poses/
                calib/
            segment_name_2/
            ...
    """
    
    def __init__(self, root_dir, split='train', cameras=None, transform=None):
        """
        Args:
            root_dir (str): Root directory containing extracted segments.
            split (str): 'train' or 'val' (currently loads all found segments).
            cameras (list): List of camera names to load. Default: ['FRONT', 'FRONT_LEFT', 'FRONT_RIGHT', 'SIDE_LEFT', 'SIDE_RIGHT']
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.root_dir = root_dir
        self.transform = transform
        
        if cameras is None:
            self.cameras = ['FRONT', 'FRONT_LEFT', 'FRONT_RIGHT', 'SIDE_LEFT', 'SIDE_RIGHT']
        else:
            self.cameras = cameras
            
        self.samples = []
        self._load_dataset()
        
    def _load_dataset(self):
        # Find all segment directories
        segment_dirs = sorted([d for d in glob.glob(os.path.join(self.root_dir, '*')) if os.path.isdir(d)])
        
        if not segment_dirs:
            print(f"Warning: No segment directories found in {self.root_dir}")
            return

        for seg_dir in segment_dirs:
            segment_name = os.path.basename(seg_dir)
            
            # Assuming files are named by frame index: 000000.png, 000001.png ...
            # We can check one camera folder to get available frames
            ref_cam_dir = os.path.join(seg_dir, 'images', self.cameras[0])
            if not os.path.exists(ref_cam_dir):
                print(f"Warning: Reference camera dir {ref_cam_dir} not found. Skipping segment {segment_name}.")
                continue
                
            frame_files = sorted(glob(os.path.join(ref_cam_dir, '*.png')))
            
            for frame_path in frame_files:
                frame_id = os.path.splitext(os.path.basename(frame_path))[0]
                
                # Verify all requested cameras exist for this frame
                all_cams_exist = True
                image_paths = {}
                
                for cam in self.cameras:
                    img_p = os.path.join(seg_dir, 'images', cam, f'{frame_id}.png')
                    if not os.path.exists(img_p):
                        all_cams_exist = False
                        break
                    image_paths[cam] = img_p
                
                if not all_cams_exist:
                    continue
                    
                pose_path = os.path.join(seg_dir, 'poses', f'{frame_id}.txt')
                calib_path = os.path.join(seg_dir, 'calib', f'{frame_id}.txt')
                
                if not os.path.exists(pose_path) or not os.path.exists(calib_path):
                    continue
                    
                self.samples.append({
                    'segment': segment_name,
                    'frame_id': frame_id,
                    'image_paths': image_paths,
                    'pose_path': pose_path,
                    'calib_path': calib_path
                })
                
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample_info = self.samples[idx]
        
        # Load Images
        images = {}
        for cam, path in sample_info['image_paths'].items():
            img = Image.open(path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            else:
                # Default to tensor if no transform provided
                img = transforms.ToTensor()(img)
            images[cam] = img
            
        # Load Global Pose (Vehicle to Global) - 4x4 Matrix
        # T_global_vehicle
        pose = np.loadtxt(sample_info['pose_path']).astype(np.float32)
        pose = torch.from_numpy(pose)
        
        # Load Calibration
        # This part requires parsing the text file generated by extract_waymo_data.py
        # Format:
        # Camera: FRONT
        # Extrinsic (Camera to Vehicle):
        # ... 4x4 matrix ...
        # Intrinsic (...):
        # ... 1xN array ...
        # Width: ...
        # Height: ...
        # ---
        calibs = self._parse_calib(sample_info['calib_path'])
        
        return {
            'images': images, # Dict of [C, H, W] tensors
            'pose': pose,     # [4, 4] tensor
            'calib': calibs,  # Dict of Dicts (intrinsics, extrinsics)
            'meta': {
                'segment': sample_info['segment'],
                'frame_id': sample_info['frame_id']
            }
        }
    
    def _parse_calib(self, calib_path):
        calibs = {}
        current_cam = None
        current_data = {}
        
        with open(calib_path, 'r') as f:
            lines = f.readlines()
            
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if line.startswith('Camera:'):
                current_cam = line.split(':')[1].strip()
                current_data = {}
            elif line.startswith('Extrinsic'):
                # Read next 4 lines
                ext_lines = [lines[i+1+k].strip().split() for k in range(4)]
                ext_mat = np.array(ext_lines, dtype=np.float32)
                current_data['extrinsic'] = torch.from_numpy(ext_mat)
                i += 4
            elif line.startswith('Intrinsic'):
                # Read next 1 line
                int_line = lines[i+1].strip().split()
                int_arr = np.array(int_line, dtype=np.float32)
                current_data['intrinsic'] = torch.from_numpy(int_arr)
                i += 1
            elif line.startswith('Width:'):
                current_data['width'] = int(line.split(':')[1].strip())
            elif line.startswith('Height:'):
                current_data['height'] = int(line.split(':')[1].strip())
            elif line.startswith('---'):
                if current_cam and current_cam in self.cameras:
                    calibs[current_cam] = current_data
            
            i += 1
            
        # Add last camera if file doesn't end with ---
        # (Though our extractor puts --- after each)
        
        return calibs

# Example Usage
if __name__ == "__main__":
    # Dummy test if directory exists
    dataset_root = "/workspace/waymo_extracted_data"
    if os.path.exists(dataset_root):
        dataset = WaymoExtractedDataset(dataset_root)
        print(f"Dataset length: {len(dataset)}")
        
        if len(dataset) > 0:
            sample = dataset[0]
            print("Sample keys:", sample.keys())
            print("Images keys:", sample['images'].keys())
            print("Pose shape:", sample['pose'].shape)
            print("Calib keys:", sample['calib'].keys())
            print("Front Cam Intrinsic:", sample['calib']['FRONT']['intrinsic'])
    else:
        print(f"Root directory {dataset_root} does not exist. Please run extract_waymo_data.py first.")
