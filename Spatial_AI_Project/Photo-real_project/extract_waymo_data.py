"""
Waymo E2E Dataset "Aggressive" Extractor
- Priority: tf.train.SequenceExample > tf.train.Example
- Detection: Checks JPEG Magic Header (FF D8) + Size > 10KB (Ignores key names if needed)
- Output: Images, Empty Masks, JSON Stats
"""

import os
import tensorflow as tf
import numpy as np
import cv2
import argparse
import json
from tqdm import tqdm
from glob import glob

# TF ë¡œê·¸ ì–µì œ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def infer_camera_name(key):
    """í‚¤ ì´ë¦„ì—ì„œ ì¹´ë©”ë¼ ì´ë¦„ì„ ì¶”ë¡ , ì‹¤íŒ¨ ì‹œ í‚¤ ìì²´ë¥¼ ì‚¬ìš©"""
    key_upper = key.upper()
    if 'FRONT_LEFT' in key_upper: return 'FRONT_LEFT'
    if 'FRONT_RIGHT' in key_upper: return 'FRONT_RIGHT'
    if 'SIDE_LEFT' in key_upper: return 'SIDE_LEFT'
    if 'SIDE_RIGHT' in key_upper: return 'SIDE_RIGHT'
    if 'FRONT' in key_upper: return 'FRONT'
    
    # 5ê°œ ì¹´ë©”ë¼ ìˆœì„œ ì¶”ì • (Waymo í‘œì¤€ ì¸ë±ìŠ¤)
    if key == '0' or key == 'image_0': return 'FRONT'
    if key == '1' or key == 'image_1': return 'FRONT_LEFT'
    if key == '2' or key == 'image_2': return 'FRONT_RIGHT'
    if key == '3' or key == 'image_3': return 'SIDE_LEFT'
    if key == '4' or key == 'image_4': return 'SIDE_RIGHT'
    
    # ì¶”ë¡  ë¶ˆê°€ ì‹œ íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë°˜í™˜
    return key.replace('/', '_').replace('.', '_')

def is_image_data(byte_data):
    """
    ë°ì´í„°ê°€ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸í•˜ëŠ” ê°•ë ¥í•œ ê²€ì‚¬
    1. í¬ê¸°ê°€ 5KB ì´ìƒì¸ê°€?
    2. JPEG í—¤ë”(FF D8)ë¡œ ì‹œì‘í•˜ëŠ”ê°€?
    """
    if len(byte_data) < 5120: # 5KB ë¯¸ë§Œì€ ì´ë¯¸ì§€ ì•„ë‹˜
        return False
    
    # JPEG Header check (Magic Number)
    if byte_data.startswith(b'\xff\xd8'):
        return True
    
    # PNG Header check
    if byte_data.startswith(b'\x89PNG'):
        return True
        
    return False

def extract_universal(tfrecord_path, output_dir):
    print(f"ğŸš€ Processing: {os.path.basename(tfrecord_path)}")
    ensure_dir(output_dir)
    
    dataset = tf.data.TFRecordDataset(tfrecord_path, compression_type='')
    
    # í†µê³„ìš© ë³€ìˆ˜
    stats = {}
    total_images_saved = 0
    records_processed = 0

    for i, raw_record in enumerate(tqdm(dataset, desc="Scanning Records")):
        records_processed += 1
        record_bytes = raw_record.numpy()
        
        # =========================================================
        # STRATEGY 1: SequenceExample (Video/Time-series) - Priority
        # =========================================================
        try:
            seq_ex = tf.train.SequenceExample()
            seq_ex.ParseFromString(record_bytes)
            
            # --- 1. Scenario ID ì¶”ì¶œ ---
            context = seq_ex.context.feature
            scenario_id = f"segment_{i}"
            
            # ID í‚¤ í›„ë³´êµ° ê²€ìƒ‰
            for id_key in ['scenario/id', 'scenario_id', 'context.name', 'segment_id']:
                if id_key in context:
                    val = context[id_key].bytes_list.value
                    if val:
                        scenario_id = val[0].decode('utf-8')
                        break
            
            # --- 2. ì´ë¯¸ì§€ í‚¤ ìë™ ê°ì§€ (feature_lists ë‚´ë¶€) ---
            feature_lists = seq_ex.feature_lists.feature_list
            image_keys = []
            
            # ëª¨ë“  í‚¤ë¥¼ ë’¤ì ¸ì„œ "ì´ë¯¸ì§€ìŠ¤ëŸ¬ìš´" ë°ì´í„°ë¥¼ ì°¾ìŒ
            for key, feat_list in feature_lists.items():
                if len(feat_list.feature) > 0:
                    first_feat = feat_list.feature[0]
                    if first_feat.bytes_list.value:
                        first_data = first_feat.bytes_list.value[0]
                        # [í•µì‹¬] í‚¤ ì´ë¦„ ë¬´ê´€í•˜ê²Œ ë°ì´í„° ë‚´ìš©ìœ¼ë¡œ íŒë³„
                        if is_image_data(first_data):
                            image_keys.append(key)

            # ì´ë¯¸ì§€ê°€ ë°œê²¬ë˜ë©´ Sequence ì¶”ì¶œ ëª¨ë“œ ì‹¤í–‰
            if image_keys:
                # í†µê³„ ì´ˆê¸°í™”
                if scenario_id not in stats:
                    stats[scenario_id] = {'count': 0, 'timestamps': []}
                
                # Timestamp ì°¾ê¸° (ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©)
                timestamps = []
                # Feature list ì¤‘ ê¸¸ì´ê°€ ê°€ì¥ ê¸´ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ ê¸¸ì´ ì‚°ì •
                seq_len = max([len(feature_lists[k].feature) for k in image_keys])
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ë¦¬ìŠ¤íŠ¸ê°€ ë”°ë¡œ ìˆëŠ”ì§€ í™•ì¸
                ts_key = None
                for k in feature_lists.keys():
                    if 'timestamp' in k and len(feature_lists[k].feature) == seq_len:
                        ts_key = k
                        break
                
                # --- í”„ë ˆì„ ìˆœíšŒ ë° ì €ì¥ ---
                for t in range(seq_len):
                    # Timestamp ê²°ì •
                    curr_ts = t
                    if ts_key:
                        ts_val = feature_lists[ts_key].feature[t].int64_list.value
                        if ts_val: curr_ts = ts_val[0]
                    
                    # í†µê³„ ì €ì¥
                    stats[scenario_id]['timestamps'].append(curr_ts)
                    stats[scenario_id]['count'] += 1
                    
                    for key in image_keys:
                        f_list = feature_lists[key].feature
                        if t >= len(f_list): continue
                        if not f_list[t].bytes_list.value: continue
                        
                        img_bytes = f_list[t].bytes_list.value[0]
                        cam_name = infer_camera_name(key)
                        
                        # ì´ë¯¸ì§€ ë””ì½”ë”©
                        np_arr = np.frombuffer(img_bytes, np.uint8)
                        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                        
                        if img is not None:
                            # ê²½ë¡œ: output/scenario_id/images/CAM/timestamp.png
                            img_dir = os.path.join(output_dir, scenario_id, 'images', cam_name)
                            mask_dir = os.path.join(output_dir, scenario_id, 'masks', cam_name)
                            ensure_dir(img_dir)
                            ensure_dir(mask_dir)
                            
                            fname = f"{curr_ts}.png"
                            
                            # ì´ë¯¸ì§€ ì €ì¥
                            cv2.imwrite(os.path.join(img_dir, fname), img)
                            
                            # ë§ˆìŠ¤í¬ ì €ì¥ (Black)
                            h, w = img.shape[:2]
                            mask = np.zeros((h, w), dtype=np.uint8)
                            cv2.imwrite(os.path.join(mask_dir, fname), mask)
                            
                            total_images_saved += 1
                
                continue # SequenceExample ì²˜ë¦¬ ì„±ê³µ ì‹œ ë‹¤ìŒ ë ˆì½”ë“œë¡œ

        except Exception as e:
            # SequenceExample íŒŒì‹± ìì²´ê°€ ì‹¤íŒ¨í•˜ë©´ Exampleë¡œ ë„˜ì–´ê°
            pass

        # =========================================================
        # STRATEGY 2: Example (Snapshot/Frame) - Fallback
        # =========================================================
        try:
            ex = tf.train.Example()
            ex.ParseFromString(record_bytes)
            features = ex.features.feature
            
            # ID ì¶”ì¶œ
            scenario_id = f"segment_{i//200}"
            if 'scenario/id' in features:
                scenario_id = features['scenario/id'].bytes_list.value[0].decode('utf-8')
            
            # Timestamp ì¶”ì¶œ
            curr_ts = i
            if 'timestamp_micros' in features:
                curr_ts = features['timestamp_micros'].int64_list.value[0]

            # ì´ë¯¸ì§€ í‚¤ ì°¾ê¸° (ë‚´ìš© ê¸°ë°˜)
            image_keys = []
            for key, feat in features.items():
                if feat.bytes_list.value:
                    if is_image_data(feat.bytes_list.value[0]):
                        image_keys.append(key)
            
            if image_keys:
                if scenario_id not in stats:
                    stats[scenario_id] = {'count': 0, 'timestamps': []}
                stats[scenario_id]['count'] += 1
                stats[scenario_id]['timestamps'].append(curr_ts)

                for key in image_keys:
                    img_bytes = features[key].bytes_list.value[0]
                    cam_name = infer_camera_name(key)
                    
                    np_arr = np.frombuffer(img_bytes, np.uint8)
                    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                    
                    if img is not None:
                        img_dir = os.path.join(output_dir, scenario_id, 'images', cam_name)
                        mask_dir = os.path.join(output_dir, scenario_id, 'masks', cam_name)
                        ensure_dir(img_dir)
                        ensure_dir(mask_dir)
                        
                        fname = f"{curr_ts}.png"
                        cv2.imwrite(os.path.join(img_dir, fname), img)
                        
                        h, w = img.shape[:2]
                        mask = np.zeros((h, w), dtype=np.uint8)
                        cv2.imwrite(os.path.join(mask_dir, fname), mask)
                        
                        total_images_saved += 1

        except Exception:
            pass

    # --- ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ ---
    print("\n" + "="*50)
    print("ğŸ“Š Extraction Statistics Report")
    print("="*50)
    
    if total_images_saved == 0:
        print("âŒ CRITICAL FAILURE: No images were extracted.")
        print("   Possible reasons:")
        print("   1. File contains NO images (LiDAR only or Motion dataset).")
        print("   2. Images are compressed in a format OpenCV cannot read (unlikely).")
        return

    print(f"âœ… Total Images Saved: {total_images_saved}")
    print(f"âœ… Total Scenarios Found: {len(stats)}")
    print(f"âœ… Total Records Processed: {records_processed}")
    
    print("\n[Scenario Detail]")
    for sid, data in list(stats.items())[:5]: # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
        ts_list = sorted(data['timestamps'])
        start_ts = ts_list[0] if ts_list else "N/A"
        end_ts = ts_list[-1] if ts_list else "N/A"
        print(f"  - ID: {sid}")
        print(f"    Frames: {data['count']}")
        print(f"    Timestamp Range: {start_ts} ~ {end_ts}")
    
    if len(stats) > 5:
        print(f"  ... and {len(stats) - 5} more scenarios")
    
    # í†µê³„ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    stats_file = os.path.join(output_dir, 'extraction_stats.json')
    with open(stats_file, 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"\nğŸ’¾ Statistics saved to: {stats_file}")

def main():
    parser = argparse.ArgumentParser(
        description='Waymo E2E Dataset "Aggressive" Extractor - Extracts images from TFRecords without requiring waymo_open_dataset package'
    )
    parser.add_argument('input_path', type=str, help='Path to .tfrecord file or directory containing .tfrecord files')
    parser.add_argument('output_dir', type=str, help='Directory to save extracted data')
    
    args = parser.parse_args()
    
    input_path = args.input_path
    output_dir = args.output_dir
    
    if os.path.isdir(input_path):
        tfrecord_files = sorted(glob(os.path.join(input_path, '*.tfrecord')))
    else:
        tfrecord_files = [input_path]
        
    print(f"Found {len(tfrecord_files)} TFRecord files.")
    
    for tf_file in tfrecord_files:
        # ê° íŒŒì¼ë§ˆë‹¤ ë³„ë„ ë””ë ‰í† ë¦¬ ìƒì„±
        segment_name = os.path.splitext(os.path.basename(tf_file))[0]
        segment_out_dir = os.path.join(output_dir, segment_name)
        
        extract_universal(tf_file, segment_out_dir)

if __name__ == '__main__':
    main()
