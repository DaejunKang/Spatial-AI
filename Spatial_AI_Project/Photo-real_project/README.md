# Photo-real Project: Waymo Open Dataset Processing & Inpainting Pipeline

Waymo Open Datasetì„ ë‹¤ìš´ë¡œë“œ, íŒŒì‹±, ì „ì²˜ë¦¬í•˜ê³ , ë™ì  ê°ì²´ ì œê±°ë¥¼ ìœ„í•œ ê³ ê¸‰ ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•˜ëŠ” í†µí•© íˆ´í‚·ì…ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- ğŸ“¥ Waymo Open Dataset ìë™ ë‹¤ìš´ë¡œë“œ
- ğŸ“Š TFRecord íŒŒì‹± ë° ì´ë¯¸ì§€/ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
- ğŸ”„ ë‹¤ì–‘í•œ í¬ë§· ë³€í™˜ (COLMAP, NRE, 3DGS)
- ğŸ¨ **3ë‹¨ê³„ ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸** (ì‹œê³„ì—´ ëˆ„ì  â†’ ê¸°í•˜í•™ì  ê°€ì´ë“œ â†’ AI ìƒì„±)
- ğŸ¤– ìƒì„±í˜• AI ëª¨ë¸ í•™ìŠµ ë°ì´í„°ì…‹ ë¹Œë”
- ğŸ—ï¸ 3D ì¬êµ¬ì„± ë° USD ë³€í™˜

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Photo-real_project/
â”œâ”€â”€ download/                           # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
â”‚   â””â”€â”€ download_waymo.py              # Waymo ë°ì´í„° ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ parsing/                            # ë°ì´í„° íŒŒì‹±/ì¶”ì¶œ
â”‚   â”œâ”€â”€ extract_waymo_data.py          # ì´ë¯¸ì§€/ë§ˆìŠ¤í¬ ì¶”ì¶œ + JSON ë©”íƒ€ë°ì´í„°
â”‚   â”œâ”€â”€ extract_waymo_data_minimal.py  # ê²½ëŸ‰ ë²„ì „ (TF ì˜ì¡´ì„± ìµœì†Œí™”)
â”‚   â”œâ”€â”€ waymo_utils.py                 # ê³µí†µ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
â”‚   â””â”€â”€ test_minimal_converter.py      # ë³€í™˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ preprocessing/                      # ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜
â”‚   â”œâ”€â”€ waymo2colmap.py                # COLMAP í¬ë§· ë³€í™˜ê¸°
â”‚   â”œâ”€â”€ waymo2nre.py                   # NRE í¬ë§· ë³€í™˜ê¸° (ê¶Œì¥)
â”‚   â”œâ”€â”€ create_nre_pairs.py            # NRE í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±
â”‚   â”œâ”€â”€ segmentation.py                # SegFormer ê¸°ë°˜ ë™ì  ê°ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜
â”‚   â””â”€â”€ run_preprocessing.py           # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
â”‚
â”œâ”€â”€ Inpainting/                         # ğŸ†• ê³ ê¸‰ ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ step1_temporal_accumulation.py # ì‹œê³„ì—´ ì •ì  í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ëˆ„ì 
â”‚   â”œâ”€â”€ step2_geometric_guide.py       # RANSAC ê¸°ë°˜ ê¸°í•˜í•™ì  ê°€ì´ë“œ ìƒì„±
â”‚   â”œâ”€â”€ step3_final_inpainting.py      # Multi-view consistent AI ì¸í˜ì¸íŒ…
â”‚   â”œâ”€â”€ training_dataset_builder.py    # LoRA/ControlNet í•™ìŠµ ë°ì´í„°ì…‹ ë¹Œë”
â”‚   â””â”€â”€ README.md                      # ìƒì„¸ ì¸í˜ì¸íŒ… ê°€ì´ë“œ
â”‚
â”œâ”€â”€ dataset.py                          # ë°ì´í„°ì…‹ ê´€ë¦¬ ëª¨ë“ˆ
â”œâ”€â”€ reconstruction.py                   # 3D ì¬êµ¬ì„± (3DGS â†’ USD ë³€í™˜)
â”œâ”€â”€ README.md                           # ğŸ“– ì´ ë¬¸ì„œ
â”œâ”€â”€ README_WAYMO_CONVERSION.md         # ìƒì„¸ ë³€í™˜ ê°€ì´ë“œ
â””â”€â”€ README_MINIMAL.md                  # Minimal ë²„ì „ ê°€ì´ë“œ
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### 1. í™˜ê²½ ì„¤ì •

#### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Python 3.7+ (ê¶Œì¥: 3.9 ë˜ëŠ” 3.10)
- CUDA ì§€ì› GPU (ì¸í˜ì¸íŒ…/í•™ìŠµìš©, ì„ íƒ)
- Waymo Open Dataset ê³„ì • (ë‹¤ìš´ë¡œë“œìš©)

#### ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/DaejunKang/Spatial-AI.git
cd Spatial-AI/Spatial_AI_Project/Photo-real_project

# ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜
pip install numpy opencv-python tqdm

# Waymo Open Dataset ì„¤ì¹˜
pip install waymo-open-dataset-tf-2-11-0

# ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸ìš© íŒ¨í‚¤ì§€
pip install open3d scikit-learn

# (ì„ íƒ) ìƒì„±í˜• AI ëª¨ë¸
pip install torch torchvision transformers diffusers accelerate

# (ì„ íƒ) 3DGS ì¬êµ¬ì„±
pip install diff-gaussian-rasterization simple-knn
```

---

## ğŸ“– ì „ì²´ ì›Œí¬í”Œë¡œìš°

```mermaid
graph LR
    A[Waymo Raw Data] --> B[Download]
    B --> C[Parsing]
    C --> D[Preprocessing]
    D --> E[Inpainting Step 1]
    E --> F[Inpainting Step 2]
    F --> G[Inpainting Step 3]
    G --> H[Clean Background Images]
    H --> I[Training Dataset]
    I --> J[Train AI Models]
```

---

## ğŸ“¥ Step 1: ë°ì´í„° ë‹¤ìš´ë¡œë“œ

Waymo Open Datasetì„ Google Cloud Storageì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

```bash
# Google Cloud SDK ì¸ì¦ (ì²˜ìŒ 1íšŒë§Œ)
gcloud auth login

# ìƒ˜í”Œ ì„¸ê·¸ë¨¼íŠ¸ 1ê°œ ë‹¤ìš´ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)
python download/download_waymo.py ./data/waymo/raw --split training --limit 1

# ì „ì²´ í•™ìŠµ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
python download/download_waymo.py ./data/waymo/raw --split training
```

**ì¶œë ¥:**
```
./data/waymo/raw/
â””â”€â”€ segment-xxxxxx.tfrecord
```

**ìƒì„¸ ê°€ì´ë“œ:** [README_WAYMO_CONVERSION.md](README_WAYMO_CONVERSION.md)

---

## ğŸ“Š Step 2: ë°ì´í„° íŒŒì‹±

TFRecord íŒŒì¼ì—ì„œ ì´ë¯¸ì§€, ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°, ë™ì  ê°ì²´ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

### Option A: Minimal ë²„ì „ (ê¶Œì¥, TensorFlow ì˜ì¡´ì„± ìµœì†Œí™”)

```bash
python parsing/extract_waymo_data_minimal.py \
    ./data/waymo/raw \
    ./data/waymo/extracted
```

### Option B: í‘œì¤€ ë²„ì „ (TensorFlow í•„ìš”)

```bash
python parsing/extract_waymo_data.py \
    ./data/waymo/raw \
    ./data/waymo/extracted
```

**ì¶œë ¥:**
```
./data/waymo/extracted/
â”œâ”€â”€ images/FRONT/*.png          # ì¹´ë©”ë¼ë³„ ì´ë¯¸ì§€
â”œâ”€â”€ masks/FRONT/*.png           # ë™ì  ê°ì²´ ë§ˆìŠ¤í¬
â”œâ”€â”€ poses/vehicle_poses.json   # Vehicle pose
â””â”€â”€ calibration/intrinsics_extrinsics.json  # ì¹´ë©”ë¼ calibration
```

**ìƒì„¸ ê°€ì´ë“œ:** [README_MINIMAL.md](README_MINIMAL.md)

---

## ğŸ”„ Step 3: ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜

ë‹¤ì–‘í•œ 3D ì¬êµ¬ì„± íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ í¬ë§· ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### 3.1 NRE (Neural Rendering Engine) í¬ë§· ë³€í™˜ (ê¶Œì¥)

3D Gaussian Splatting ë° Neural Renderingì— ìµœì í™”ëœ í¬ë§·ì…ë‹ˆë‹¤.

```bash
python preprocessing/waymo2nre.py \
    ./data/waymo/raw \
    ./data/waymo/nre_format \
    --prefix seq0_
```

**ì¶œë ¥:**
```
./data/waymo/nre_format/
â”œâ”€â”€ images/                    # JPEG ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ seq0_000001_FRONT.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ poses/                     # í”„ë ˆì„ë³„ ì§€ì˜¤ë©”íŠ¸ë¦¬ ì •ë³´
â”‚   â”œâ”€â”€ seq0_000001.json
â”‚   â””â”€â”€ ...
â””â”€â”€ objects/                   # í”„ë ˆì„ë³„ ë™ì  ê°ì²´ ì •ë³´
    â”œâ”€â”€ seq0_000001.json
    â””â”€â”€ ...
```

**Pose JSON êµ¬ì¡°:**
```json
{
    "frame_idx": 1,
    "timestamp": 1234567890.123456,
    "ego_velocity": {
        "linear": [1.5, 0.0, 0.0],
        "angular": [0.0, 0.0, 0.05]
    },
    "cameras": {
        "FRONT": {
            "img_path": "images/seq0_000001_FRONT.jpg",
            "width": 1920,
            "height": 1280,
            "intrinsics": [fx, fy, cx, cy, k1, k2, p1, p2, k3],
            "pose": [...]  // 4x4 matrix (flatten)
        }
    }
}
```

### 3.2 NRE í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±

3DGS í•™ìŠµì„ ìœ„í•œ train/val ë¶„í•  ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
python preprocessing/create_nre_pairs.py \
    ./data/waymo/nre_format \
    --output_dir ./data/waymo/nre_format \
    --val_interval 10
```

**ì¶œë ¥:**
```
./data/waymo/nre_format/
â”œâ”€â”€ train.json                 # í•™ìŠµ ë°ì´í„° (90%)
â””â”€â”€ val.json                   # ê²€ì¦ ë°ì´í„° (10%)
```

### 3.3 COLMAP í¬ë§· ë³€í™˜

COLMAP SfM íŒŒì´í”„ë¼ì¸ê³¼ í˜¸í™˜ë˜ëŠ” í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```bash
python preprocessing/waymo2colmap.py \
    ./data/waymo/extracted \
    ./data/waymo/colmap_format
```

**ì¶œë ¥:**
```
./data/waymo/colmap_format/
â”œâ”€â”€ cameras.txt                # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
â”œâ”€â”€ images.txt                 # ì´ë¯¸ì§€ í¬ì¦ˆ
â””â”€â”€ points3D.txt              # ë¹ˆ íŒŒì¼ (SfM ì „ìš©)
```

### 3.4 ë™ì  ê°ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜ (ì„ íƒ)

SegFormerë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì  ê°ì²´ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
python preprocessing/run_preprocessing.py \
    ./data/waymo/nre_format \
    --use_segformer \
    --device cuda
```

---

## ğŸ¨ Step 4: ê³ ê¸‰ ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸

ë™ì  ê°ì²´ë¥¼ ì œê±°í•˜ê³  ì •ì  ë°°ê²½ìœ¼ë¡œ ì±„ìš°ëŠ” 3ë‹¨ê³„ ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

### 4.1 Step 1: ì‹œê³„ì—´ ëˆ„ì  (Temporal Accumulation)

ì—¬ëŸ¬ í”„ë ˆì„ì˜ ì •ì  ì˜ì—­ì„ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ëˆ„ì í•˜ì—¬ ë‹¤ì‹œ íˆ¬ì˜í•©ë‹ˆë‹¤.

```bash
cd Inpainting

python step1_temporal_accumulation.py \
    ../data/waymo/nre_format \
    --voxel_size 0.05 \
    --sample_interval 5
```

**ì•Œê³ ë¦¬ì¦˜:**
1. Forward Pass: ì •ì  ì˜ì—­ì˜ 3D í¬ì¸íŠ¸ë¥¼ ì „ì—­ ì¢Œí‘œê³„ë¡œ ëˆ„ì 
2. Voxel downsamplingìœ¼ë¡œ ì¤‘ë³µ ì œê±°
3. Backward Pass: ì „ì—­ í¬ì¸íŠ¸ë¥¼ ê° í”„ë ˆì„ì— ì¬íˆ¬ì˜
4. Z-bufferingìœ¼ë¡œ ê°€ì‹œì„± ì²˜ë¦¬

**ì¶œë ¥:**
```
./data/waymo/nre_format/
â””â”€â”€ step1_warped/              # ì‹œê³„ì—´ ëˆ„ì  ê²°ê³¼
    â”œâ”€â”€ seq0_000001_FRONT.png
    â””â”€â”€ ...
```

### 4.2 Step 2: ê¸°í•˜í•™ì  ê°€ì´ë“œ ìƒì„± (Geometric Guide)

RANSAC ê¸°ë°˜ í‰ë©´ í”¼íŒ…ìœ¼ë¡œ ë‚¨ì€ êµ¬ë©ì˜ depthë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

```bash
python step2_geometric_guide.py \
    ../data/waymo/nre_format \
    --ground_ratio 0.6
```

**ì•Œê³ ë¦¬ì¦˜:**
1. Step 1 ê²°ê³¼ì—ì„œ êµ¬ë© ê°ì§€ (ê²€ì€ìƒ‰ í”½ì…€)
2. ì´ë¯¸ì§€ í•˜ë‹¨ ì˜ì—­ì—ì„œ ë°”ë‹¥ í‰ë©´ ìƒ˜í”Œë§
3. RANSACìœ¼ë¡œ í‰ë©´ ë°©ì •ì‹ í”¼íŒ…: Z = aX + bY + c
4. êµ¬ë© ì˜ì—­ì˜ depth ì˜ˆì¸¡

**ì¶œë ¥:**
```
./data/waymo/nre_format/
â”œâ”€â”€ step2_depth_guide/         # ê¸°í•˜í•™ì ìœ¼ë¡œ ì±„ì›Œì§„ depth
â”‚   â”œâ”€â”€ seq0_000001_FRONT.png
â”‚   â””â”€â”€ ...
â””â”€â”€ step2_hole_masks/          # êµ¬ë© ì˜ì—­ ë§ˆìŠ¤í¬
    â”œâ”€â”€ seq0_000001_FRONT.png
    â””â”€â”€ ...
```

### 4.3 Step 3: ìµœì¢… ì¸í˜ì¸íŒ… (Final Inpainting)

Step 1ê³¼ Step 2ì˜ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìƒì„±í˜• AI ê¸°ë°˜ ìµœì¢… ì¸í˜ì¸íŒ…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```bash
# OpenCV ê¸°ë°˜ (ë¹ ë¥´ê³  ê°€ë²¼ì›€)
python step3_final_inpainting.py ../data/waymo/nre_format

# Stable Diffusion ê¸°ë°˜ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼)
python step3_final_inpainting.py ../data/waymo/nre_format --use_ai
```

**ì•Œê³ ë¦¬ì¦˜:**
1. ì›ë³¸ ì´ë¯¸ì§€ + Step 1 warped ì´ë¯¸ì§€ ìœµí•©
2. Step 2 êµ¬ë© ë§ˆìŠ¤í¬ë¡œ ì¸í˜ì¸íŒ… ì˜ì—­ ê²°ì •
3. Stable Diffusionìœ¼ë¡œ ìƒì„± (ë˜ëŠ” OpenCV inpainting)
4. í…ìŠ¤ì²˜ ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼

**ì¶œë ¥:**
```
./data/waymo/nre_format/
â””â”€â”€ step3_final_inpainted/     # ìµœì¢… ì™„ì„± ì´ë¯¸ì§€
    â”œâ”€â”€ seq0_000001_FRONT.png
    â””â”€â”€ ...
```

**ìƒì„¸ ê°€ì´ë“œ:** [Inpainting/README.md](Inpainting/README.md)

---

## ğŸ¤– Step 5: ìƒì„±í˜• AI í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± (ì„ íƒ)

ì¸í˜ì¸íŒ… ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ LoRA ë° ControlNet í•™ìŠµìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.

```bash
cd Inpainting

# ëª¨ë“  ë°ì´í„°ì…‹ ìƒì„±
python training_dataset_builder.py \
    ../data/waymo/nre_format \
    --mode all \
    --max_samples 1000

# LoRA ë°ì´í„°ì…‹ë§Œ
python training_dataset_builder.py \
    ../data/waymo/nre_format \
    --mode lora \
    --lora_trigger "WaymoStyle autonomous driving scene"

# ControlNet Canny ë°ì´í„°ì…‹ë§Œ
python training_dataset_builder.py \
    ../data/waymo/nre_format \
    --mode controlnet_canny \
    --canny_low 100 \
    --canny_high 200

# ControlNet Depth ë°ì´í„°ì…‹ë§Œ
python training_dataset_builder.py \
    ../data/waymo/nre_format \
    --mode controlnet_depth
```

**ì¶œë ¥:**
```
./data/waymo/nre_format/gen_ai_train/
â”œâ”€â”€ lora_dataset/
â”‚   â”œâ”€â”€ 000000.jpg             # ê¹¨ë—í•œ ë°°ê²½ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ 000001.jpg
â”‚   â””â”€â”€ metadata.jsonl         # HuggingFace format
â”‚
â””â”€â”€ controlnet_dataset/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ 000000.jpg         # Target ì´ë¯¸ì§€
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ conditioning_images/
    â”‚   â”œâ”€â”€ 000000_cond.png    # Canny edge or Depth
    â”‚   â””â”€â”€ ...
    â””â”€â”€ metadata.jsonl         # HuggingFace format
```

**metadata.jsonl ì˜ˆì‹œ:**

LoRA:
```json
{"file_name": "000000.jpg", "text": "WaymoStyle road", "original_file": "seq0_000001_FRONT.jpg"}
```

ControlNet:
```json
{"text": "high quality road scene", "image": "train/000000.jpg", "conditioning_image": "conditioning_images/000000_cond.png", "original_file": "seq0_000001_FRONT.jpg"}
```

### ìƒì„±í˜• AI ëª¨ë¸ í•™ìŠµ

HuggingFace Diffusers í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ í˜¸í™˜ë©ë‹ˆë‹¤.

**LoRA í•™ìŠµ:**
```bash
python train_text_to_image_lora.py \
    --pretrained_model_name_or_path="runwayml/stable-diffusion-v1-5" \
    --train_data_dir="gen_ai_train/lora_dataset" \
    --caption_column="text" \
    --resolution=512 \
    --train_batch_size=4 \
    --num_train_epochs=100 \
    --learning_rate=1e-4 \
    --output_dir="./output/waymo_lora"
```

**ControlNet í•™ìŠµ:**
```bash
python train_controlnet.py \
    --pretrained_model_name_or_path="runwayml/stable-diffusion-v1-5" \
    --train_data_dir="gen_ai_train/controlnet_dataset" \
    --conditioning_image_column="conditioning_image" \
    --image_column="image" \
    --caption_column="text" \
    --resolution=512 \
    --train_batch_size=4 \
    --num_train_epochs=100 \
    --learning_rate=1e-5 \
    --output_dir="./output/waymo_controlnet"
```

---

## ğŸ—ï¸ Step 6: 3D ì¬êµ¬ì„± (ì„ íƒ)

3D Gaussian Splattingìœ¼ë¡œ ì¬êµ¬ì„±í•˜ê³  USD í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```bash
# 3DGS í•™ìŠµ (ë³„ë„ ì €ì¥ì†Œ í•„ìš”)
# https://github.com/graphdeco-inria/gaussian-splatting

# ì¬êµ¬ì„± ê²°ê³¼ë¥¼ USDë¡œ ë³€í™˜
python reconstruction.py \
    ./output/3dgs/point_cloud.ply \
    ./output/scene.usd
```

---

## ğŸ“Š í¬ë§· ë¹„êµ

| ê¸°ëŠ¥ | NRE | COLMAP | Extract |
|------|-----|--------|---------|
| TensorFlow ë¶ˆí•„ìš” | âœ… | âœ… | âŒ |
| ë™ì  ê°ì²´ ë¼ë²¨ | âœ… | âŒ | âŒ |
| Rolling Shutter | âœ… | âŒ | âŒ |
| ì†ë„ ì •ë³´ | âœ… | âŒ | âŒ |
| ë§ˆìŠ¤í¬ ìƒì„± | âŒ | âŒ | âœ… |
| SfM í˜¸í™˜ | âŒ | âœ… | âŒ |
| 3DGS í˜¸í™˜ | âœ… | âœ… | âœ… |

**ê¶Œì¥ í¬ë§·:** `waymo2nre.py` (NRE)

---

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •

### Depth ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°

Inpainting íŒŒì´í”„ë¼ì¸ì—ì„œ depth ë§µì´ ì—†ìœ¼ë©´ pseudo depthë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ìœ„í•´ monocular depth estimationì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# TODO: Monocular depth estimation í†µí•©
from depth_anything import DepthEstimator
depth_estimator = DepthEstimator()
depth = depth_estimator.predict(image)
```

### Stable Diffusion Inpainting í†µí•©

`Inpainting/step3_final_inpainting.py`ì—ì„œ ìƒì„±í˜• AIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:

```python
# _initialize_generative_model() ë©”ì†Œë“œ ìˆ˜ì •
from diffusers import StableDiffusionInpaintPipeline
import torch

model_id = "stabilityai/stable-diffusion-2-inpainting"
self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16
)
self.pipe = self.pipe.to("cuda")
```

ì‹¤í–‰:
```bash
pip install diffusers transformers accelerate
python step3_final_inpainting.py /data --use_ai
```

### ë©”ëª¨ë¦¬ ìµœì í™”

ëŒ€ìš©ëŸ‰ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì‹œ:

1. **Step 1**: `--sample_interval` ì¦ê°€, `--voxel_size` ì¦ê°€
2. **Step 2**: `--ground_ratio` ì¡°ì •
3. **Dataset Builder**: `--max_samples` ì œí•œ

```bash
# ì˜ˆì‹œ: ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ
python step1_temporal_accumulation.py /data \
    --sample_interval 10 \
    --voxel_size 0.1

python training_dataset_builder.py /data \
    --mode all \
    --max_samples 500
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### TensorFlow ê´€ë ¨ ì˜¤ë¥˜

```bash
# TensorFlow 2.11.0 ì„¤ì¹˜ (Python 3.7-3.10)
pip install tensorflow==2.11.0

# ë˜ëŠ” Minimal Mode ì‚¬ìš©
python parsing/extract_waymo_data_minimal.py ...
```

### Waymo Dataset íŒ¨í‚¤ì§€ ì˜¤ë¥˜

```bash
# í˜¸í™˜ë˜ëŠ” ë²„ì „ ì„¤ì¹˜
pip uninstall waymo-open-dataset-tf-2-11-0
pip install waymo-open-dataset-tf-2-11-0==1.5.2
```

### "No points accumulated" ê²½ê³  (Inpainting Step 1)

**ì›ì¸:**
- Depth íŒŒì¼ì´ ì—†ê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë¨
- Maskê°€ ëª¨ë‘ 0 (ë™ì )ìœ¼ë¡œ ë˜ì–´ ìˆìŒ
- Pose íŒŒì¼ í˜•ì‹ì´ ë‹¤ë¦„

**í•´ê²°:**
1. Depth íŒŒì¼ ê²½ë¡œ í™•ì¸: `data_root/depths/`
2. Mask í™•ì¸: 255 ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
3. Pose JSON êµ¬ì¡° í™•ì¸

### "Insufficient valid depth points" ê²½ê³  (Inpainting Step 2)

**í•´ê²°:**
1. `--ground_ratio` ê°’ì„ ì¡°ì • (ì˜ˆ: 0.5ë¡œ ë‚®ì¶¤)
2. Step 1ì˜ voxel_sizeë¥¼ ì¤„ì—¬ ë” ì¡°ë°€í•œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
3. `--no_lidar` ì˜µì…˜ìœ¼ë¡œ pseudo depth ì‚¬ìš©

### Open3D ì˜¤ë¥˜

```bash
# Open3D ì„¤ì¹˜ ë˜ëŠ” ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade open3d

# CUDA out of memory ì‹œ
export OPEN3D_CPU_RENDERING=1
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

- í•œ ë²ˆì— í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ì²˜ë¦¬
- ì´ë¯¸ì§€ í’ˆì§ˆ ë‚®ì¶”ê¸° (JPEG quality ì¡°ì •)
- `--sample_interval` ì¦ê°€

---

## ğŸ“š ìƒì„¸ ë¬¸ì„œ

- **[README_WAYMO_CONVERSION.md](README_WAYMO_CONVERSION.md)**: ë°ì´í„° ë³€í™˜ ìƒì„¸ ê°€ì´ë“œ
- **[README_MINIMAL.md](README_MINIMAL.md)**: Minimal ë²„ì „ ê°€ì´ë“œ
- **[Inpainting/README.md](Inpainting/README.md)**: ì¸í˜ì¸íŒ… íŒŒì´í”„ë¼ì¸ ìƒì„¸ ê°€ì´ë“œ

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [Waymo Open Dataset](https://waymo.com/open/)
- [COLMAP](https://colmap.github.io/)
- [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting)
- [HuggingFace Diffusers](https://github.com/huggingface/diffusers)
- [OpenCV Documentation](https://docs.opencv.org/)

---

## ğŸ“ ë¼ì´ì„¼ìŠ¤

ì´ ì½”ë“œëŠ” Waymo Open Dataset Licenseë¥¼ ë”°ë¦…ë‹ˆë‹¤.
ì›ë³¸ ë°ì´í„° ì‚¬ìš© ì‹œ [Waymo Terms of Use](https://waymo.com/open/terms/)ë¥¼ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ™ ê¸°ì—¬

ì´ìŠˆ ë° Pull Requestë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

ì €ì¥ì†Œ: [https://github.com/DaejunKang/Spatial-AI](https://github.com/DaejunKang/Spatial-AI)

---

## ğŸ“§ ë¬¸ì˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜: GitHub Issuesë¥¼ í†µí•´ ì—°ë½ ì£¼ì„¸ìš”.
